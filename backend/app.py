from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import json
import subprocess
import sys
import platform
from pathlib import Path
import hashlib
from logger import logger
from dotenv import load_dotenv
from sqlalchemy import create_engine, Column, String, Boolean, Integer, DateTime
from sqlalchemy.orm import declarative_base
from sqlalchemy.orm import sessionmaker
from functools import wraps
from datetime import datetime
from supabase import create_client, Client

# Charger les variables d'environnement
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

app = Flask(__name__)

# Configuration de la base de donn√©es Supabase
DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///users.db')
SECRET_KEY = os.getenv('SECRET_KEY', 'dev-secret-key')
TRIAL_LIMIT = int(os.getenv('TRIAL_LIMIT', '3'))
ADMIN_KEY = os.getenv('ADMIN_KEY', 'dev-admin-key')

app.config['SECRET_KEY'] = SECRET_KEY

# Configuration SQLAlchemy (connexion s√©curis√©e Supabase IPv4)
# D√©tecter le type de base de donn√©es pour les arguments de connexion
connect_args = {}
if DATABASE_URL.startswith('postgresql://'):
    connect_args = {"sslmode": "require"}

engine = create_engine(
    DATABASE_URL,
    connect_args=connect_args,
    pool_pre_ping=True,
    pool_size=5,          # Taille mod√©r√©e pour Render (√©vite surcharge)
    max_overflow=10       # Connexions temporaires suppl√©mentaires
)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# Mod√®le User pour Supabase
class User(Base):
    __tablename__ = "users"
    
    id = Column(String, primary_key=True)
    email = Column(String, unique=True, nullable=False)
    password_hash = Column(String, nullable=False)
    premium = Column(Boolean, default=False)
    trial_count = Column(Integer, default=0)
    created_at = Column(DateTime, default=datetime.utcnow)

# Cr√©er les tables si elles n'existent pas
Base.metadata.create_all(bind=engine)

# Configuration CORS pour les origines frontend (production + d√©veloppement)
CORS(app, resources={r"/api/*": {"origins": ["*"]}},
     supports_credentials=True)

# Chemins bas√©s sur le r√©pertoire du script
BASE_DIR = Path(__file__).resolve().parent
USERS_FILE = BASE_DIR / "users.json"
CHANNELS_FILE = BASE_DIR / "channels.txt"
URLS_FILE = BASE_DIR / "urls.txt"
TRANSCRIPTS_DIR = BASE_DIR / "transcripts"
TRANSCRIBE_LOG = BASE_DIR / "transcribe.out"

# Chemins pour Render (dossier /tmp writable)
RENDER_TMP_DIR = Path("/tmp")
RENDER_TRANSCRIPTS_DIR = RENDER_TMP_DIR / "transcripts"
RENDER_LOG_FILE = RENDER_TMP_DIR / "transcribe.out"

# Cr√©er le dossier transcripts s'il n'existe pas
TRANSCRIPTS_DIR.mkdir(exist_ok=True)

# Variables globales pour suivre les processus en cours
SCRAPE_PROCESS = None
TRANSCRIBE_PROCESS = None

def load_users():
    """Charge les utilisateurs depuis le fichier JSON"""
    if USERS_FILE.exists():
        with open(USERS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_users(users):
    """Sauvegarde les utilisateurs dans le fichier JSON"""
    with open(USERS_FILE, 'w', encoding='utf-8') as f:
        json.dump(users, f, indent=2)

def hash_password(password):
    """Hash simple du mot de passe (pour MVP)"""
    return hashlib.sha256(password.encode()).hexdigest()

# Fonctions utilitaires pour la gestion des utilisateurs avec SQLAlchemy
def get_db():
    """Obtient une session de base de donn√©es"""
    db = SessionLocal()
    try:
        return db
    finally:
        pass

def get_user_by_email(email):
    """R√©cup√®re un utilisateur par email"""
    db = get_db()
    try:
        return db.query(User).filter(User.email == email).first()
    finally:
        db.close()

def create_user(email, password_hash):
    """Cr√©e un nouvel utilisateur"""
    db = get_db()
    try:
        import uuid
        user = User(
            id=str(uuid.uuid4()),
            email=email,
            password_hash=password_hash,
            premium=False,
            trial_count=0
        )
        db.add(user)
        db.commit()
        return user
    except Exception as e:
        db.rollback()
        raise e
    finally:
        db.close()

def increment_trial_count(email):
    """Incr√©mente le compteur d'essais d'un utilisateur"""
    db = get_db()
    try:
        user = db.query(User).filter(User.email == email).first()
        if user:
            user.trial_count += 1
            db.commit()
            return user.trial_count
        return None
    except Exception as e:
        db.rollback()
        raise e
    finally:
        db.close()

def can_user_transcribe(email):
    """V√©rifie si un utilisateur peut transcrire (premium ou essais restants)"""
    user = get_user_by_email(email)
    if not user:
        return False, "Utilisateur non trouv√©"
    
    if user.premium:
        return True, "Compte premium"
    
    if user.trial_count < TRIAL_LIMIT:
        return True, f"Essais restants: {TRIAL_LIMIT - user.trial_count}"
    
    return False, f"Limite d'essais atteinte ({TRIAL_LIMIT})"

def _spawn_transcriber(script_path: Path):
    """
    Lance le script de transcription de mani√®re compatible Windows/Linux
    Redirige stdout et stderr vers le fichier de log /tmp/transcribe.out (Render)
    """
    global TRANSCRIBE_PROCESS
    
    try:
        # V√©rifier que le script existe
        if not script_path.exists():
            raise FileNotFoundError(f"Script non trouv√©: {script_path}")
        
        # Cr√©er le dossier /tmp/transcripts s'il n'existe pas
        RENDER_TRANSCRIPTS_DIR.mkdir(exist_ok=True)
        
        # Utiliser le fichier de log dans /tmp (writable sur Render)
        log_file_path = RENDER_LOG_FILE
        
        # Logger tous les chemins utilis√©s
        logger.log_transcription("", "CHEMINS", f"Script: {script_path}")
        logger.log_transcription("", "CHEMINS", f"Base dir: {BASE_DIR}")
        logger.log_transcription("", "CHEMINS", f"Sortie transcripts: {RENDER_TRANSCRIPTS_DIR}")
        logger.log_transcription("", "CHEMINS", f"Log file: {log_file_path}")
        
        print(f"üîß Chemins utilis√©s:")
        print(f"   Script: {script_path}")
        print(f"   Base dir: {BASE_DIR}")
        print(f"   Sortie transcripts: {RENDER_TRANSCRIPTS_DIR}")
        print(f"   Log file: {log_file_path}")
        
        # Lancer le processus avec python3 (compatible Render)
        TRANSCRIBE_PROCESS = subprocess.Popen(
            ["python3", str(script_path)],
            cwd=str(BASE_DIR),
            stdout=open(log_file_path, 'w', encoding='utf-8'),
            stderr=subprocess.STDOUT,  # Rediriger stderr vers stdout
            text=True,
            bufsize=1,  # Ligne par ligne
            universal_newlines=True
        )
        
        logger.log_transcription("", "LANC√â", f"PID: {TRANSCRIBE_PROCESS.pid}, Log: {log_file_path}")
        print(f"Processus de transcription lanc√© avec PID: {TRANSCRIBE_PROCESS.pid}")
        print(f"Sortie redirig√©e vers: {log_file_path}")
        
        return TRANSCRIBE_PROCESS
        
    except Exception as e:
        logger.log_error(f"Erreur lors du lancement de la transcription: {str(e)}")
        raise e

# D√©corateur pour l'authentification admin
def admin_required(f):
    @wraps(f)
    def wrapper(*args, **kwargs):
        key = request.headers.get("X-Admin-Key")
        if key != ADMIN_KEY:
            return jsonify({"error": "forbidden"}), 403
        return f(*args, **kwargs)
    return wrapper

@app.route("/api/health", methods=["GET"])
def health():
    """Healthcheck endpoint"""
    logger.log_info("Healthcheck appel√©")
    return jsonify({"status": "ok"})

@app.route("/api/test-transcription", methods=["POST"])
def test_transcription():
    """Test de transcription pour diagnostiquer les probl√®mes"""
    try:
        # Cr√©er un fichier urls.txt de test avec une URL simple
        test_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"  # Rick Roll pour test
        with open(URLS_FILE, 'w', encoding='utf-8') as f:
            f.write(test_url)
        
        print(f"Test de transcription avec: {test_url}")
        
        # Lancer le script de transcription
        script_path = BASE_DIR / "lancer_bot (2).bat"
        result = subprocess.run(
            ["cmd", "/c", str(script_path)],
            cwd=str(BASE_DIR),
            capture_output=True,
            text=True,
            timeout=60
        )
        
        return jsonify({
            "returncode": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "script_path": str(script_path),
            "urls_file_exists": URLS_FILE.exists(),
            "urls_content": URLS_FILE.read_text(encoding='utf-8') if URLS_FILE.exists() else "Fichier non trouv√©"
        }), 200
        
    except Exception as e:
        return jsonify({"error": f"Erreur lors du test: {str(e)}"}), 500

@app.route("/api/debug", methods=["GET"])
def debug():
    """Debug endpoint pour v√©rifier les fichiers"""
    files_status = {
        "scrape_script": (BASE_DIR / "scrape_channel_videos.py").exists(),
        "transcribe_script": (BASE_DIR / "lancer_bot (2).bat").exists(),
        "bot_script": (BASE_DIR / "bot_yttotranscript.py").exists(),
        "channels_file": CHANNELS_FILE.exists(),
        "urls_file": URLS_FILE.exists(),
        "transcripts_dir": TRANSCRIPTS_DIR.exists(),
        "transcripts_count": len(list(TRANSCRIPTS_DIR.glob("*.txt"))) if TRANSCRIPTS_DIR.exists() else 0,
        "dependencies": {
            "playwright": False,
            "rich": False,
            "yt_dlp": False,
            "requests": False
        }
    }
    
    # V√©rifier les d√©pendances Python
    try:
        import playwright
        files_status["dependencies"]["playwright"] = True
    except ImportError:
        pass
    
    try:
        import rich
        files_status["dependencies"]["rich"] = True
    except ImportError:
        pass
    
    try:
        import yt_dlp
        files_status["dependencies"]["yt_dlp"] = True
    except ImportError:
        pass
    
    try:
        import requests
        files_status["dependencies"]["requests"] = True
    except ImportError:
        pass
    
    return jsonify(files_status)

@app.route("/api/auth/register", methods=["POST"])
def register_supabase():
    """Inscription d'un utilisateur avec Supabase Auth"""
    data = request.get_json()
    email = data.get("email")
    password = data.get("password")

    if not email or not password:
        return jsonify({"error": "Email et mot de passe requis"}), 400

    try:
        response = supabase.auth.sign_up({"email": email, "password": password})
        return jsonify({
            "message": "Inscription r√©ussie",
            "user": getattr(response, "user", None)
        }), 201
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/auth/login", methods=["POST"])
def login_supabase():
    """Connexion d'un utilisateur via Supabase Auth"""
    data = request.get_json()
    email = data.get("email")
    password = data.get("password")

    if not email or not password:
        return jsonify({"error": "Email et mot de passe requis"}), 400

    try:
        response = supabase.auth.sign_in_with_password({"email": email, "password": password})
        return jsonify({
            "message": "Connexion r√©ussie",
            "session": getattr(response, "session", None),
            "user": getattr(response, "user", None)
        }), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 401

@app.route("/api/auth/me", methods=["GET"])
def get_me():
    """R√©cup√®re l'utilisateur actuellement connect√©"""
    try:
        user = supabase.auth.get_user()
        return jsonify(user), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 401

@app.route("/api/scrape/channel", methods=["POST"])
def scrape_channel():
    """Scrape une cha√Æne YouTube en utilisant le script existant"""
    global SCRAPE_PROCESS
    data = request.get_json()
    channel = data.get("channel")
    
    logger.log_api_call("/api/scrape/channel", "POST", data)
    
    if not channel:
        logger.log_error("Channel requis manquant")
        return jsonify({"error": "Channel requis"}), 400
    
    try:
        # Nettoyer les anciens fichiers avant de commencer
        if URLS_FILE.exists():
            URLS_FILE.unlink()
            logger.log_file_operation("SUPPRESSION", str(URLS_FILE), "Nettoyage avant nouveau scraping")
        
        # √âcrire la cha√Æne dans channels.txt
        with open(CHANNELS_FILE, 'w', encoding='utf-8') as f:
            f.write(channel)
        
        logger.log_file_operation("√âCRITURE", str(CHANNELS_FILE), f"Contenu: {channel}")
        
        # Lancer le script de scraping en arri√®re-plan
        script_path = BASE_DIR / "scrape_channel_videos.py"
        logger.log_scraping(channel, 0, "D√âBUT")
        print(f"Lancement du scraping pour: {channel}")
        
        # Lancer en arri√®re-plan avec Popen
        SCRAPE_PROCESS = subprocess.Popen(
            ["python", str(script_path)],
            cwd=str(BASE_DIR),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        logger.log_scraping(channel, 0, "LANC√â")
        print(f"Processus de scraping lanc√© avec PID: {SCRAPE_PROCESS.pid}")
        
        return jsonify({
            "message": "Scraping d√©marr√©",
            "status": "started",
            "process_id": SCRAPE_PROCESS.pid
        }), 202
        
    except Exception as e:
        print(f"Exception lors du scraping: {str(e)}")
        return jsonify({"error": f"Erreur lors du scraping: {str(e)}"}), 500

@app.route("/api/transcribe/selected", methods=["POST"])
def transcribe_selected():
    """Transcrire seulement les vid√©os s√©lectionn√©es"""
    global TRANSCRIBE_PROCESS
    data = request.get_json()
    urls = data.get("urls", [])
    user_email = data.get("email")  # Email de l'utilisateur connect√©
    
    logger.log_api_call("/api/transcribe/selected", "POST", data)
    
    if not urls:
        logger.log_error("Aucune URL fournie pour la transcription")
        return jsonify({"error": "Aucune URL fournie"}), 400
    
    # V√©rifier les limites d'utilisation si un email est fourni
    if user_email:
        can_transcribe, message = check_transcription_limit(user_email)
        if not can_transcribe:
            logger.log_warning(f"Tentative de transcription bloqu√©e pour {user_email}: {message}")
            return jsonify({
                "error": f"Limite d'utilisation atteinte: {message}",
                "trial_limit_reached": True
            }), 403
    
    try:
        # √âcrire les URLs s√©lectionn√©es dans urls.txt
        with open(URLS_FILE, 'w', encoding='utf-8', newline='\n') as f:
            f.write('\n'.join(urls))
        
        logger.log_file_operation("√âCRITURE", str(URLS_FILE), f"URLs s√©lectionn√©es: {len(urls)}")
        print(f"Transcription de {len(urls)} vid√©os s√©lectionn√©es")
        
        # Lancer le script de transcription ORIGINAL avec Playwright
        script_path = BASE_DIR / "bot_yttotranscript.py"
        
        logger.log_transcription("", "D√âBUT", f"Script: {script_path}")
        print(f"Lancement de la transcription pour {len(urls)} vid√©os...")
        print(f"Script utilis√©: {script_path}")
        print(f"URLs √† transcrire: {urls}")
        
        # V√©rifier que urls.txt contient bien les URLs
        if URLS_FILE.exists():
            with open(URLS_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"Contenu de urls.txt: {content[:200]}...")
        
        try:
            # Utiliser la nouvelle fonction compatible Windows/Linux
            TRANSCRIBE_PROCESS = _spawn_transcriber(script_path)
            
            print("Le script de transcription va traiter les vid√©os...")
            
            # Attendre que le processus se termine (pour Render)
            import time
            time.sleep(2)  # Attendre un peu pour que le script d√©marre
            
            # V√©rifier le statut du processus
            poll_result = TRANSCRIBE_PROCESS.poll()
            if poll_result is not None:
                # Le processus s'est termin√©, v√©rifier les fichiers g√©n√©r√©s
                files_generated = 0
                if RENDER_TRANSCRIPTS_DIR.exists():
                    transcript_files = list(RENDER_TRANSCRIPTS_DIR.glob("*.txt"))
                    files_generated = len(transcript_files)
                
                logger.log_transcription("", "TERMIN√â", f"Code: {poll_result}, Fichiers: {files_generated}")
                
                return jsonify({
                    "message": f"‚úÖ Transcription termin√©e ! {files_generated} fichier(s) g√©n√©r√©(s)",
                    "process_id": TRANSCRIBE_PROCESS.pid,
                    "status": "completed",
                    "files_generated": files_generated,
                    "log_file": str(RENDER_LOG_FILE),
                    "transcripts_dir": str(RENDER_TRANSCRIPTS_DIR)
                }), 200
            else:
                # Le processus est encore en cours
                return jsonify({
                    "message": f"Transcription d√©marr√©e ! Le script va traiter {len(urls)} vid√©o(s)",
                    "process_id": TRANSCRIBE_PROCESS.pid,
                    "status": "started",
                    "log_file": str(RENDER_LOG_FILE),
                    "note": "V√©rifiez les logs pour suivre la progression"
                }), 202
                
        except Exception as e:
            print(f"Erreur lors du lancement: {e}")
            return jsonify({
                "error": f"Erreur lors du lancement de la transcription: {str(e)}"
            }), 500
        
    except Exception as e:
        print(f"Exception lors de la transcription: {str(e)}")
        return jsonify({"error": f"Erreur lors de la transcription: {str(e)}"}), 500

@app.route("/api/transcribe/bulk", methods=["POST"])
def transcribe_bulk():
    """Lance la transcription en bulk avec le script existant"""
    global TRANSCRIBE_PROCESS
    data = request.get_json() or {}
    user_email = data.get("email")  # Email de l'utilisateur connect√©
    
    # V√©rifier les limites d'utilisation si un email est fourni
    if user_email:
        can_transcribe, message = check_transcription_limit(user_email)
        if not can_transcribe:
            logger.log_warning(f"Tentative de transcription bulk bloqu√©e pour {user_email}: {message}")
            return jsonify({
                "error": f"Limite d'utilisation atteinte: {message}",
                "trial_limit_reached": True
            }), 403
    
    try:
        # Utiliser directement le script Python (compatible Windows/Linux)
        script_path = BASE_DIR / "bot_yttotranscript.py"
        print(f"Lancement de la transcription: {script_path}")
        
        # V√©rifier que le script existe
        if not script_path.exists():
            return jsonify({"error": "Script de transcription non trouv√©"}), 500
        
        # Utiliser la nouvelle fonction compatible Windows/Linux
        try:
            TRANSCRIBE_PROCESS = _spawn_transcriber(script_path)
            
            print(f"Processus de transcription lanc√© avec PID: {TRANSCRIBE_PROCESS.pid}")
            
            # Attendre que le processus se termine (pour Render)
            import time
            time.sleep(2)  # Attendre un peu pour que le script d√©marre
            
            # V√©rifier le statut du processus
            poll_result = TRANSCRIBE_PROCESS.poll()
            if poll_result is not None:
                # Le processus s'est termin√©, v√©rifier les fichiers g√©n√©r√©s
                files_generated = 0
                if RENDER_TRANSCRIPTS_DIR.exists():
                    transcript_files = list(RENDER_TRANSCRIPTS_DIR.glob("*.txt"))
                    files_generated = len(transcript_files)
                
                logger.log_transcription("", "TERMIN√â", f"Code: {poll_result}, Fichiers: {files_generated}")
                
                return jsonify({
                    "message": f"‚úÖ Transcription termin√©e ! {files_generated} fichier(s) g√©n√©r√©(s)",
                    "process_id": TRANSCRIBE_PROCESS.pid,
                    "status": "completed",
                    "files_generated": files_generated,
                    "log_file": str(RENDER_LOG_FILE),
                    "transcripts_dir": str(RENDER_TRANSCRIPTS_DIR)
                }), 200
            else:
                # Le processus est encore en cours
                return jsonify({
                    "message": "Transcription d√©marr√©e ! Le script va traiter les vid√©os en arri√®re-plan",
                    "process_id": TRANSCRIBE_PROCESS.pid,
                    "status": "started",
                    "log_file": str(RENDER_LOG_FILE),
                    "note": "V√©rifiez les logs pour suivre la progression"
                }), 202
                
        except FileNotFoundError as e:
            print(f"Erreur fichier non trouv√©: {e}")
            return jsonify({"error": f"Script de transcription non trouv√©: {e}"}), 500
        except Exception as e:
            print(f"Erreur lors du lancement: {e}")
            return jsonify({"error": f"Erreur lors du lancement de la transcription: {str(e)}"}), 500
        
    except Exception as e:
        print(f"Exception lors de la transcription: {str(e)}")
        return jsonify({"error": f"Erreur lors de la transcription: {str(e)}"}), 500

def get_video_info_from_url(url):
    """Extrait l'ID vid√©o depuis l'URL YouTube"""
    import re
    video_id_match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    return video_id_match.group(1) if video_id_match else None

def get_video_title(video_id):
    """R√©cup√®re le titre d'une vid√©o YouTube via l'API publique"""
    try:
        import requests
        import re
        
        # Utiliser l'API publique de YouTube (sans cl√© API)
        url = f"https://www.youtube.com/watch?v={video_id}"
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            # Extraire le titre depuis la page HTML
            title_match = re.search(r'<title>([^<]+)</title>', response.text)
            if title_match:
                title = title_match.group(1)
                # Nettoyer le titre (enlever " - YouTube")
                title = title.replace(' - YouTube', '').strip()
                return title
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration du titre pour {video_id}: {e}")
    
    return None

@app.route("/api/scraped-urls", methods=["GET"])
def get_scraped_urls():
    """R√©cup√®re les URLs scrap√©es depuis urls.txt avec infos vid√©o"""
    try:
        urls = []
        if URLS_FILE.exists():
            with open(URLS_FILE, 'r', encoding='utf-8') as f:
                urls = [line.strip() for line in f.readlines() if line.strip()]
        
        # Enrichir avec les infos vid√©o
        videos_with_info = []
        for i, url in enumerate(urls):
            video_id = get_video_info_from_url(url)
            title = get_video_title(video_id) if video_id else f"Vid√©o {i + 1}"
            videos_with_info.append({
                "url": url,
                "video_id": video_id,
                "title": title,
                "thumbnail": f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg" if video_id else None
            })
        
        return jsonify({"videos": videos_with_info, "count": len(videos_with_info)}), 200
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la lecture des URLs: {str(e)}"}), 500

@app.route("/api/transcripts", methods=["GET"])
def list_transcripts():
    """Liste tous les fichiers de transcription disponibles"""
    try:
        files = []
        if TRANSCRIPTS_DIR.exists():
            for file_path in TRANSCRIPTS_DIR.glob("*.txt"):
                stat = file_path.stat()
                files.append({
                    "name": file_path.name,
                    "path": str(file_path.relative_to(BASE_DIR)),
                    "size": stat.st_size,
                    "modified": stat.st_mtime
                })
        
        return jsonify({"files": files}), 200
        
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la lecture des fichiers: {str(e)}"}), 500

@app.route("/api/transcripts/content", methods=["GET"])
def get_transcript_content():
    """R√©cup√®re le contenu d'un fichier de transcription"""
    path = request.args.get("path")
    
    if not path:
        return jsonify({"error": "Param√®tre path requis"}), 400
    
    try:
        # S√©curiser le chemin pour √©viter les acc√®s en dehors du dossier transcripts
        safe_path = Path(path)
        if ".." in str(safe_path) or not str(safe_path).startswith("transcripts"):
            return jsonify({"error": "Chemin non autoris√©"}), 400
        
        file_path = BASE_DIR / safe_path
        
        if not file_path.exists() or not file_path.is_file():
            return jsonify({"error": "Fichier non trouv√©"}), 404
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return jsonify({"content": content}), 200
        
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la lecture du fichier: {str(e)}"}), 500

@app.route("/api/transcripts/download", methods=["GET"])
def download_all_transcripts():
    """T√©l√©charge tous les fichiers de transcription dans un ZIP"""
    try:
        import zipfile
        import tempfile
        
        # Cr√©er un fichier ZIP temporaire
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            zip_path = temp_zip.name
        
        # Cr√©er le ZIP avec tous les fichiers de transcription
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            if TRANSCRIPTS_DIR.exists():
                for file_path in TRANSCRIPTS_DIR.glob("*.txt"):
                    zipf.write(file_path, file_path.name)
        
        # Retourner le fichier ZIP
        return send_from_directory(
            os.path.dirname(zip_path),
            os.path.basename(zip_path),
            as_attachment=True,
            download_name="transcriptions.zip"
        )
        
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la cr√©ation du ZIP: {str(e)}"}), 500

@app.route("/api/logs", methods=["GET"])
def get_logs():
    """R√©cup√®re les logs de la session actuelle"""
    try:
        log_file = BASE_DIR / "session_log.txt"
        if log_file.exists():
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = f.read()
            return jsonify({"logs": logs}), 200
        else:
            return jsonify({"logs": "Aucun log disponible"}), 200
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la lecture des logs: {str(e)}"}), 500

@app.route("/api/scrape/status", methods=["GET"])
def get_scrape_status():
    """V√©rifie le statut du scraping en cours"""
    global SCRAPE_PROCESS
    try:
        running = False
        if SCRAPE_PROCESS is not None:
            # V√©rifier si le processus est encore en cours
            poll_result = SCRAPE_PROCESS.poll()
            if poll_result is None:
                running = True
            else:
                # Processus termin√©, nettoyer
                print(f"DEBUG: Processus scraping termin√© avec code: {poll_result}")
                SCRAPE_PROCESS = None
        
        # V√©rifier le signal de fin d'enrichissement
        completion_file = BASE_DIR / "scraping_completed.txt"
        if completion_file.exists():
            try:
                with open(completion_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                if content.startswith("completed:"):
                    # Enrichissement termin√©, nettoyer le signal
                    completion_file.unlink()
                    print("DEBUG: Signal de fin d'enrichissement d√©tect√©, processus termin√©")
                    running = False
                    if SCRAPE_PROCESS is not None:
                        try:
                            SCRAPE_PROCESS.terminate()
                            print("DEBUG: Processus de scraping termin√©")
                        except:
                            pass
                        SCRAPE_PROCESS = None
            except Exception as e:
                print(f"DEBUG: Erreur lecture signal de fin: {e}")
        
        # Compter les URLs dans urls.txt
        url_count = 0
        last_modified = None
        if URLS_FILE.exists():
            try:
                with open(URLS_FILE, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    # Essayer de lire comme JSON
                    try:
                        videos_data = json.loads(content)
                        if isinstance(videos_data, list):
                            url_count = len(videos_data)
                        else:
                            # Ancien format
                            urls = [line.strip() for line in content.splitlines() if line.strip()]
                            url_count = len(urls)
                    except (json.JSONDecodeError, ValueError):
                        # Ancien format
                        urls = [line.strip() for line in content.splitlines() if line.strip()]
                        url_count = len(urls)
                last_modified = URLS_FILE.stat().st_mtime
                print(f"DEBUG: {url_count} vid√©os trouv√©es dans urls.txt")
            except Exception as e:
                print(f"DEBUG: Erreur lecture urls.txt: {e}")
                url_count = 0
        
        return jsonify({
            "running": running,
            "count": url_count,
            "lastModified": last_modified
        }), 200
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la v√©rification du statut: {str(e)}"}), 500

@app.route("/api/scrape/urls", methods=["GET"])
def get_scrape_urls():
    """R√©cup√®re les URLs scrap√©es en temps r√©el avec titres r√©els"""
    try:
        videos_with_info = []
        if URLS_FILE.exists():
            with open(URLS_FILE, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                
            # Essayer de lire comme JSON d'abord (nouveau format)
            try:
                videos_data = json.loads(content)
                if isinstance(videos_data, list):
                    # Nouveau format JSON avec titres r√©els
                    videos_with_info = []
                    for video in videos_data:
                        videos_with_info.append({
                            "url": video.get("url", ""),
                            "video_id": video.get("video_id", ""),
                            "title": video.get("title", "Titre non disponible"),
                            "thumbnail": video.get("thumbnail", f"https://img.youtube.com/vi/{video.get('video_id', '')}/mqdefault.jpg" if video.get('video_id') else None)
                        })
                    print(f"DEBUG: Lecture JSON de {len(videos_with_info)} vid√©os avec titres r√©els")
                else:
                    raise ValueError("Format JSON invalide")
            except (json.JSONDecodeError, ValueError, KeyError):
                # Fallback: ancien format (une URL par ligne)
                print("DEBUG: Format ancien d√©tect√©, conversion en cours...")
                urls = [line.strip() for line in content.splitlines() if line.strip()]
                for i, url in enumerate(urls):
                    video_id = get_video_info_from_url(url)
                    videos_with_info.append({
                        "url": url,
                        "video_id": video_id,
                        "title": f"Vid√©o {i + 1}",
                        "thumbnail": f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg" if video_id else None
                    })
                print(f"DEBUG: Conversion de {len(videos_with_info)} URLs (format ancien)")
        else:
            print("DEBUG: urls.txt n'existe pas")
        
        print(f"DEBUG: Retour de {len(videos_with_info)} vid√©os")
        
        return jsonify({
            "urls": videos_with_info,
            "count": len(videos_with_info),
            "lastModified": URLS_FILE.stat().st_mtime if URLS_FILE.exists() else None
        }), 200
    except Exception as e:
        print(f"DEBUG: Erreur dans get_scrape_urls: {e}")
        return jsonify({"error": f"Erreur lors de la lecture des URLs: {str(e)}"}), 500

@app.route("/api/transcribe/status", methods=["GET"])
def get_transcribe_status():
    """V√©rifie le statut de la transcription en cours"""
    global TRANSCRIBE_PROCESS
    try:
        running = False
        if TRANSCRIBE_PROCESS is not None:
            # V√©rifier si le processus est encore en cours
            poll_result = TRANSCRIBE_PROCESS.poll()
            if poll_result is None:
                running = True
            else:
                # Processus termin√©, nettoyer
                print(f"DEBUG: Processus transcription termin√© avec code: {poll_result}")
                TRANSCRIBE_PROCESS = None
        
        # Compter les fichiers de transcription
        files_count = 0
        files = []
        if TRANSCRIPTS_DIR.exists():
            transcript_files = list(TRANSCRIPTS_DIR.glob("*.txt"))
            files_count = len(transcript_files)
            files = [f.name for f in transcript_files]
            print(f"DEBUG: {files_count} fichiers de transcription trouv√©s: {files}")
        else:
            print("DEBUG: Dossier transcripts n'existe pas")
        
        return jsonify({
            "running": running,
            "filesCount": files_count,
            "files": files
        }), 200
    except Exception as e:
        print(f"DEBUG: Erreur dans get_transcribe_status: {e}")
        return jsonify({"error": f"Erreur lors de la v√©rification du statut: {str(e)}"}), 500

@app.route("/api/transcribe/log", methods=["GET"])
def transcribe_log():
    """Permet de lire les derni√®res lignes du log de transcription."""
    try:
        n = int(request.args.get("n", 200))
        
        # Utiliser le fichier de log Render si disponible, sinon le local
        log_file = RENDER_LOG_FILE if RENDER_LOG_FILE.exists() else TRANSCRIBE_LOG
        
        if not log_file.exists():
            return jsonify({"log": "<aucun log>", "log_file": str(log_file)}), 200
        
        with open(log_file, "r", encoding="utf-8") as f:
            lines = f.readlines()
        
        return jsonify({
            "log": "".join(lines[-n:]),
            "log_file": str(log_file),
            "total_lines": len(lines)
        }), 200
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la lecture du log: {str(e)}"}), 500

@app.route("/api/transcription/status", methods=["GET"])
def get_transcription_status():
    """V√©rifie le statut de la transcription en cours (legacy)"""
    try:
        completion_file = BASE_DIR / "transcription_completed.txt"
        if completion_file.exists():
            with open(completion_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            if content.startswith("completed:"):
                parts = content.split(":")
                success_count = int(parts[1]) if len(parts) > 1 else 0
                total_count = int(parts[2]) if len(parts) > 2 else 0
                
                # Supprimer le fichier de signal
                completion_file.unlink()
                
                return jsonify({
                    "status": "completed",
                    "success_count": success_count,
                    "total_count": total_count
                }), 200
            else:
                return jsonify({"status": "unknown"}), 200
        else:
            return jsonify({"status": "running"}), 200
    except Exception as e:
        return jsonify({"error": f"Erreur lors de la v√©rification du statut: {str(e)}"}), 500

@app.route("/api/transcripts/clean", methods=["POST"])
def clean_old_transcripts():
    """Nettoie les anciens fichiers de transcription"""
    try:
        if TRANSCRIPTS_DIR.exists():
            # Supprimer tous les fichiers .txt dans le dossier transcripts
            for file_path in TRANSCRIPTS_DIR.glob("*.txt"):
                file_path.unlink()
                logger.log_file_operation("SUPPRESSION", str(file_path), "Nettoyage anciens transcripts")
        
        return jsonify({"message": "Anciens fichiers de transcription supprim√©s"}), 200
    except Exception as e:
        return jsonify({"error": f"Erreur lors du nettoyage: {str(e)}"}), 500

@app.route("/api/scrape/urls/enriched", methods=["GET"])
def get_scrape_urls_enriched():
    """R√©cup√®re les URLs avec titres enrichis (maintenant identique √† /urls)"""
    try:
        # Maintenant que les titres sont directement dans le JSON, 
        # cet endpoint retourne la m√™me chose que /urls
        videos_with_info = []
        if URLS_FILE.exists():
            with open(URLS_FILE, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                
            # Essayer de lire comme JSON d'abord (nouveau format)
            try:
                videos_data = json.loads(content)
                if isinstance(videos_data, list):
                    # Nouveau format JSON avec titres r√©els
                    videos_with_info = []
                    for video in videos_data:
                        videos_with_info.append({
                            "url": video.get("url", ""),
                            "video_id": video.get("video_id", ""),
                            "title": video.get("title", "Titre non disponible"),
                            "thumbnail": video.get("thumbnail", f"https://img.youtube.com/vi/{video.get('video_id', '')}/mqdefault.jpg" if video.get('video_id') else None)
                        })
                    print(f"DEBUG: Lecture JSON ENRICHI de {len(videos_with_info)} vid√©os avec titres r√©els")
                else:
                    raise ValueError("Format JSON invalide")
            except (json.JSONDecodeError, ValueError, KeyError):
                # Fallback: ancien format (une URL par ligne) - enrichir avec API
                print("DEBUG: Format ancien d√©tect√©, enrichissement avec API...")
                urls = [line.strip() for line in content.splitlines() if line.strip()]
                for i, url in enumerate(urls):
                    video_id = get_video_info_from_url(url)
                    title = get_video_title(video_id) if video_id else f"Vid√©o {i + 1}"
                    videos_with_info.append({
                        "url": url,
                        "video_id": video_id,
                        "title": title,
                        "thumbnail": f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg" if video_id else None
                    })
                print(f"DEBUG: Enrichissement API de {len(videos_with_info)} URLs (format ancien)")
        else:
            print("DEBUG: urls.txt n'existe pas")
        
        print(f"DEBUG: Retour ENRICHI de {len(videos_with_info)} vid√©os")
        
        return jsonify({
            "urls": videos_with_info,
            "count": len(videos_with_info),
            "lastModified": URLS_FILE.stat().st_mtime if URLS_FILE.exists() else None
        }), 200
    except Exception as e:
        print(f"DEBUG: Erreur dans get_scrape_urls_enriched: {e}")
        return jsonify({"error": f"Erreur lors de la lecture des URLs: {str(e)}"}), 500

@app.route("/api/debug/urls", methods=["GET"])
def debug_urls():
    """Debug endpoint pour v√©rifier le contenu de urls.txt"""
    try:
        if URLS_FILE.exists():
            with open(URLS_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = [line.strip() for line in content.splitlines() if line.strip()]
            
            return jsonify({
                "exists": True,
                "content": content,
                "lines": lines,
                "count": len(lines),
                "size": len(content),
                "lastModified": URLS_FILE.stat().st_mtime
            }), 200
        else:
            return jsonify({
                "exists": False,
                "message": "urls.txt n'existe pas"
            }), 200
    except Exception as e:
        return jsonify({"error": f"Erreur: {str(e)}"}), 500

@app.route("/api/debug/transcripts", methods=["GET"])
def debug_transcripts():
    """Debug endpoint pour v√©rifier les fichiers de transcription"""
    try:
        transcript_files = []
        if TRANSCRIPTS_DIR.exists():
            for file_path in TRANSCRIPTS_DIR.glob("*.txt"):
                stat = file_path.stat()
                transcript_files.append({
                    "name": file_path.name,
                    "size": stat.st_size,
                    "modified": stat.st_mtime
                })
        
        return jsonify({
            "transcripts_dir_exists": TRANSCRIPTS_DIR.exists(),
            "transcripts_dir_path": str(TRANSCRIPTS_DIR),
            "files": transcript_files,
            "count": len(transcript_files)
        }), 200
    except Exception as e:
        return jsonify({"error": f"Erreur: {str(e)}"}), 500

# ===== ROUTES D'ADMINISTRATION =====

@app.route("/api/admin/set-premium", methods=["POST"])
@admin_required
def set_premium():
    """Active/d√©sactive le statut premium d'un utilisateur"""
    data = request.get_json()
    email = data.get("email")
    premium = bool(data.get("premium", False))
    
    if not email:
        return jsonify({"error": "Email requis"}), 400
    
    user = get_user_by_email(email)
    if not user:
        return jsonify({"error": "Utilisateur non trouv√©"}), 404
    
    # Mettre √† jour le statut premium
    db = get_db()
    try:
        user.premium = premium
        db.commit()
        logger.log_success(f"Statut premium mis √† jour pour {email}: {premium}")
        
        return jsonify({
            "message": "Statut premium mis √† jour",
            "email": email,
            "premium": premium
        }), 200
    except Exception as e:
        db.rollback()
        logger.log_error(f"Erreur mise √† jour premium: {str(e)}")
        return jsonify({"error": "Erreur lors de la mise √† jour"}), 500
    finally:
        db.close()

@app.route("/api/admin/users", methods=["GET"])
@admin_required
def list_users():
    """Liste tous les utilisateurs (admin seulement)"""
    db = get_db()
    try:
        users = db.query(User).all()
        users_data = []
        for user in users:
            users_data.append({
                "id": user.id,
                "email": user.email,
                "premium": user.premium,
                "trial_count": user.trial_count,
                "created_at": user.created_at.isoformat() if user.created_at else None
            })
        
        return jsonify({
            "users": users_data,
            "total": len(users_data)
        }), 200
    except Exception as e:
        logger.log_error(f"Erreur liste utilisateurs: {str(e)}")
        return jsonify({"error": "Erreur lors de la r√©cup√©ration des utilisateurs"}), 500
    finally:
        db.close()

@app.route("/api/admin/reset-trial", methods=["POST"])
@admin_required
def reset_trial():
    """Remet √† z√©ro le compteur d'essais d'un utilisateur"""
    data = request.get_json()
    email = data.get("email")
    
    if not email:
        return jsonify({"error": "Email requis"}), 400
    
    user = get_user_by_email(email)
    if not user:
        return jsonify({"error": "Utilisateur non trouv√©"}), 404
    
    db = get_db()
    try:
        user.trial_count = 0
        db.commit()
        logger.log_success(f"Compteur d'essais remis √† z√©ro pour {email}")
        
        return jsonify({
            "message": "Compteur d'essais remis √† z√©ro",
            "email": email,
            "trial_count": 0
        }), 200
    except Exception as e:
        db.rollback()
        logger.log_error(f"Erreur reset trial: {str(e)}")
        return jsonify({"error": "Erreur lors de la remise √† z√©ro"}), 500
    finally:
        db.close()

# ===== MODIFICATION DES ENDPOINTS DE TRANSCRIPTION =====

# Modifier l'endpoint de transcription pour v√©rifier les limites
def check_transcription_limit(email):
    """V√©rifie si l'utilisateur peut transcrire et incr√©mente le compteur si n√©cessaire"""
    can_transcribe, message = can_user_transcribe(email)
    
    if not can_transcribe:
        return False, message
    
    # Incr√©menter le compteur d'essais si l'utilisateur n'est pas premium
    user = get_user_by_email(email)
    if user and not user.premium:
        increment_trial_count(email)
        logger.log_info(f"Compteur d'essais incr√©ment√© pour {email}")
    
    return True, message

if __name__ == "__main__":
    # Configuration pour Render (production)
    port = int(os.getenv('PORT', 8000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    app.run(host="0.0.0.0", port=port, debug=debug)
